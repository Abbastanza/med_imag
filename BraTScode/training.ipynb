{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_train = pd.read_csv(\"radiomics_features_training_original.csv\")\n",
    "brats_dir = \"./BraTS2020\" \n",
    "path_train = os.path.join(brats_dir, \"BraTS2020_TrainingData\", \"MICCAI_BraTS2020_TrainingData\")\n",
    "map_train = pd.read_csv(os.path.join(path_train, \"name_mapping.csv\"))\n",
    "feat_train_perturbed = pd.read_csv(\"radiomics_features_training_perturbed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case</th>\n",
       "      <th>modality</th>\n",
       "      <th>mask_type</th>\n",
       "      <th>original_shape_Elongation</th>\n",
       "      <th>original_shape_Flatness</th>\n",
       "      <th>original_shape_LeastAxisLength</th>\n",
       "      <th>original_shape_MajorAxisLength</th>\n",
       "      <th>original_shape_Maximum2DDiameterColumn</th>\n",
       "      <th>original_shape_Maximum2DDiameterRow</th>\n",
       "      <th>original_shape_Maximum2DDiameterSlice</th>\n",
       "      <th>...</th>\n",
       "      <th>original_ngtdm_Coarseness</th>\n",
       "      <th>original_ngtdm_Complexity</th>\n",
       "      <th>original_ngtdm_Contrast</th>\n",
       "      <th>original_ngtdm_Strength</th>\n",
       "      <th>Grade</th>\n",
       "      <th>BraTS_2017_subject_ID</th>\n",
       "      <th>BraTS_2018_subject_ID</th>\n",
       "      <th>TCGA_TCIA_subject_ID</th>\n",
       "      <th>BraTS_2019_subject_ID</th>\n",
       "      <th>BraTS_2020_subject_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BraTS20_Training_082</td>\n",
       "      <td>t1</td>\n",
       "      <td>original</td>\n",
       "      <td>0.615924</td>\n",
       "      <td>0.558094</td>\n",
       "      <td>13.056671</td>\n",
       "      <td>23.395129</td>\n",
       "      <td>19.416488</td>\n",
       "      <td>26.019224</td>\n",
       "      <td>25.317978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004038</td>\n",
       "      <td>19.403883</td>\n",
       "      <td>0.012255</td>\n",
       "      <td>0.145263</td>\n",
       "      <td>HGG</td>\n",
       "      <td>Brats17_CBICA_AZD_1</td>\n",
       "      <td>Brats18_CBICA_AZD_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BraTS19_CBICA_AZD_1</td>\n",
       "      <td>BraTS20_Training_082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BraTS20_Training_082</td>\n",
       "      <td>t1ce</td>\n",
       "      <td>original</td>\n",
       "      <td>0.615924</td>\n",
       "      <td>0.558094</td>\n",
       "      <td>13.056671</td>\n",
       "      <td>23.395129</td>\n",
       "      <td>19.416488</td>\n",
       "      <td>26.019224</td>\n",
       "      <td>25.317978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004579</td>\n",
       "      <td>171.683748</td>\n",
       "      <td>0.079231</td>\n",
       "      <td>0.489439</td>\n",
       "      <td>HGG</td>\n",
       "      <td>Brats17_CBICA_AZD_1</td>\n",
       "      <td>Brats18_CBICA_AZD_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BraTS19_CBICA_AZD_1</td>\n",
       "      <td>BraTS20_Training_082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BraTS20_Training_082</td>\n",
       "      <td>t2</td>\n",
       "      <td>original</td>\n",
       "      <td>0.615924</td>\n",
       "      <td>0.558094</td>\n",
       "      <td>13.056671</td>\n",
       "      <td>23.395129</td>\n",
       "      <td>19.416488</td>\n",
       "      <td>26.019224</td>\n",
       "      <td>25.317978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>24.992246</td>\n",
       "      <td>0.016806</td>\n",
       "      <td>0.190565</td>\n",
       "      <td>HGG</td>\n",
       "      <td>Brats17_CBICA_AZD_1</td>\n",
       "      <td>Brats18_CBICA_AZD_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BraTS19_CBICA_AZD_1</td>\n",
       "      <td>BraTS20_Training_082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BraTS20_Training_082</td>\n",
       "      <td>flair</td>\n",
       "      <td>original</td>\n",
       "      <td>0.615924</td>\n",
       "      <td>0.558094</td>\n",
       "      <td>13.056671</td>\n",
       "      <td>23.395129</td>\n",
       "      <td>19.416488</td>\n",
       "      <td>26.019224</td>\n",
       "      <td>25.317978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004867</td>\n",
       "      <td>79.792367</td>\n",
       "      <td>0.021403</td>\n",
       "      <td>0.483111</td>\n",
       "      <td>HGG</td>\n",
       "      <td>Brats17_CBICA_AZD_1</td>\n",
       "      <td>Brats18_CBICA_AZD_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BraTS19_CBICA_AZD_1</td>\n",
       "      <td>BraTS20_Training_082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BraTS20_Training_244</td>\n",
       "      <td>t1</td>\n",
       "      <td>original</td>\n",
       "      <td>0.739970</td>\n",
       "      <td>0.638121</td>\n",
       "      <td>33.263382</td>\n",
       "      <td>52.127075</td>\n",
       "      <td>55.605755</td>\n",
       "      <td>62.177166</td>\n",
       "      <td>61.188234</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>262.315113</td>\n",
       "      <td>0.012017</td>\n",
       "      <td>0.353904</td>\n",
       "      <td>HGG</td>\n",
       "      <td>Brats17_TCIA_603_1</td>\n",
       "      <td>Brats18_TCIA06_603_1</td>\n",
       "      <td>TCGA-19-5958</td>\n",
       "      <td>BraTS19_TCIA06_603_1</td>\n",
       "      <td>BraTS20_Training_244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   case modality mask_type  original_shape_Elongation  \\\n",
       "0  BraTS20_Training_082       t1  original                   0.615924   \n",
       "1  BraTS20_Training_082     t1ce  original                   0.615924   \n",
       "2  BraTS20_Training_082       t2  original                   0.615924   \n",
       "3  BraTS20_Training_082    flair  original                   0.615924   \n",
       "4  BraTS20_Training_244       t1  original                   0.739970   \n",
       "\n",
       "   original_shape_Flatness  original_shape_LeastAxisLength  \\\n",
       "0                 0.558094                       13.056671   \n",
       "1                 0.558094                       13.056671   \n",
       "2                 0.558094                       13.056671   \n",
       "3                 0.558094                       13.056671   \n",
       "4                 0.638121                       33.263382   \n",
       "\n",
       "   original_shape_MajorAxisLength  original_shape_Maximum2DDiameterColumn  \\\n",
       "0                       23.395129                               19.416488   \n",
       "1                       23.395129                               19.416488   \n",
       "2                       23.395129                               19.416488   \n",
       "3                       23.395129                               19.416488   \n",
       "4                       52.127075                               55.605755   \n",
       "\n",
       "   original_shape_Maximum2DDiameterRow  original_shape_Maximum2DDiameterSlice  \\\n",
       "0                            26.019224                              25.317978   \n",
       "1                            26.019224                              25.317978   \n",
       "2                            26.019224                              25.317978   \n",
       "3                            26.019224                              25.317978   \n",
       "4                            62.177166                              61.188234   \n",
       "\n",
       "   ...  original_ngtdm_Coarseness  original_ngtdm_Complexity  \\\n",
       "0  ...                   0.004038                  19.403883   \n",
       "1  ...                   0.004579                 171.683748   \n",
       "2  ...                   0.004393                  24.992246   \n",
       "3  ...                   0.004867                  79.792367   \n",
       "4  ...                   0.000508                 262.315113   \n",
       "\n",
       "   original_ngtdm_Contrast  original_ngtdm_Strength  Grade  \\\n",
       "0                 0.012255                 0.145263    HGG   \n",
       "1                 0.079231                 0.489439    HGG   \n",
       "2                 0.016806                 0.190565    HGG   \n",
       "3                 0.021403                 0.483111    HGG   \n",
       "4                 0.012017                 0.353904    HGG   \n",
       "\n",
       "   BraTS_2017_subject_ID  BraTS_2018_subject_ID  TCGA_TCIA_subject_ID  \\\n",
       "0    Brats17_CBICA_AZD_1    Brats18_CBICA_AZD_1                   NaN   \n",
       "1    Brats17_CBICA_AZD_1    Brats18_CBICA_AZD_1                   NaN   \n",
       "2    Brats17_CBICA_AZD_1    Brats18_CBICA_AZD_1                   NaN   \n",
       "3    Brats17_CBICA_AZD_1    Brats18_CBICA_AZD_1                   NaN   \n",
       "4     Brats17_TCIA_603_1   Brats18_TCIA06_603_1          TCGA-19-5958   \n",
       "\n",
       "   BraTS_2019_subject_ID  BraTS_2020_subject_ID  \n",
       "0    BraTS19_CBICA_AZD_1   BraTS20_Training_082  \n",
       "1    BraTS19_CBICA_AZD_1   BraTS20_Training_082  \n",
       "2    BraTS19_CBICA_AZD_1   BraTS20_Training_082  \n",
       "3    BraTS19_CBICA_AZD_1   BraTS20_Training_082  \n",
       "4   BraTS19_TCIA06_603_1   BraTS20_Training_244  \n",
       "\n",
       "[5 rows x 116 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Merge features with map train to get labels\n",
    "\n",
    "data_train = feat_train.merge(map_train, left_on=\"case\", right_on=\"BraTS_2020_subject_ID\")\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features and target for training\n",
    "# Use only original features, convert to NumPy arrays\n",
    "X = data_train.filter(regex=\"original\").values\n",
    "y = data_train[\"Grade\"].values\n",
    "\n",
    "# Split data into training, validation and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return accuracy_score(y_test, y_pred), precision_score(y_test, y_pred, pos_label=\"LGG\"), recall_score(y_test, y_pred, pos_label=\"LGG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.90, Precision: 0.85, Recall: 0.67\n"
     ]
    }
   ],
   "source": [
    "# Train a logistic regression model\n",
    "param_grid = {\"C\": [0.1, 1, 10, 100]}\n",
    "model = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=5)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy, precision, recall = evaluate_model(model, X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "print(f\"Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}\")\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, \"model.pkl\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "\n",
    "results.append({\"model\": \"LogisticRegression\", \"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"params\": model.best_params_, \"n_components\": None, \"dataset\": \"original\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85, Precision: 0.80, Recall: 0.48\n"
     ]
    }
   ],
   "source": [
    "# Train a logistic regression model with PCA features\n",
    "\n",
    "param_grid = {\"logisticregression__C\": [0.1, 1, 10, 100], \"pca__n_components\": [0.95]}\n",
    "\n",
    "pipe = Pipeline([(\"pca\", PCA()), (\"logisticregression\", LogisticRegression(max_iter=1000))])\n",
    "model = GridSearchCV(pipe, param_grid, cv=5)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy, precision, recall = evaluate_model(model, X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "print(f\"Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}\")\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, \"model_pca.pkl\")\n",
    "\n",
    "results.append({\"model\": \"LogisticRegression\", \"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"params\": model.best_params_, \"n_components\": model.best_params_[\"pca__n_components\"], \"dataset\": \"original\"})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.92, Precision: 0.92, Recall: 0.70\n"
     ]
    }
   ],
   "source": [
    "# Train a random forest model\n",
    "param_grid = {\"n_estimators\": [100, 200, 300], \"max_depth\": [10, 20, 30]}\n",
    "model = GridSearchCV(RandomForestClassifier(random_state=0), param_grid, cv=5)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy, precision, recall = evaluate_model(model, X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "print(f\"Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}\")\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, \"model_rf.pkl\")\n",
    "\n",
    "results.append({\"model\": \"RandomForest\", \"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"params\": model.best_params_, \"n_components\": None, \"dataset\": \"original\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.87, Precision: 0.94, Recall: 0.48\n"
     ]
    }
   ],
   "source": [
    "# Train a random forest model with PCA features\n",
    "param_grid = {\"randomforestclassifier__n_estimators\": [100, 200, 300, 400, 500], \"randomforestclassifier__max_depth\": [10, 20, 30], \"pca__n_components\": [10, 20, 30, 40]}\n",
    "pipe = Pipeline([(\"pca\", PCA()), (\"randomforestclassifier\", RandomForestClassifier(random_state=0))])\n",
    "model = GridSearchCV(pipe, param_grid, cv=5)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy, precision, recall = evaluate_model(model, X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "print(f\"Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}\")\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, \"model_rf_pca.pkl\")\n",
    "\n",
    "results.append({\"model\": \"RandomForest\", \"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"params\": model.best_params_, \"n_components\": model.best_params_[\"pca__n_components\"], \"dataset\": \"original\"}) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models with perturbed features\n",
    "X_perturbed = feat_train_perturbed.filter(regex=\"original\").values\n",
    "y_perturbed = data_train[\"Grade\"].values\n",
    "\n",
    "X_train_perturbed, X_test_perturbed, y_train_perturbed, y_test_perturbed = train_test_split(X_perturbed, y_perturbed, test_size=0.2, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled_perturbed = scaler.fit_transform(X_train_perturbed)\n",
    "X_test_scaled_perturbed = scaler.transform(X_test_perturbed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.89, Precision: 0.80, Recall: 0.70\n"
     ]
    }
   ],
   "source": [
    "# Train logistic regression model with perturbed features\n",
    "param_grid = {\"C\": [0.1, 1, 10, 100]}\n",
    "model = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=5)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy, precision, recall = evaluate_model(model, X_train_scaled_perturbed, y_train_perturbed, X_test_scaled_perturbed, y_test_perturbed)\n",
    "print(f\"Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}\")\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, \"model_perturbed.pkl\")\n",
    "joblib.dump(scaler, \"scaler_perturbed.pkl\")\n",
    "\n",
    "results.append({\"model\": \"LogisticRegression\", \"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"params\": model.best_params_, \"n_components\": None, \"dataset\": \"perturbed\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.88, Precision: 0.86, Recall: 0.55\n"
     ]
    }
   ],
   "source": [
    "# Train logistic regression model with PCA features and perturbed features\n",
    "param_grid = {\"logisticregression__C\": [0.1, 1, 10, 100], \"pca__n_components\": [0.95]}\n",
    "pipe = Pipeline([(\"pca\", PCA()), (\"logisticregression\", LogisticRegression(max_iter=1000))])\n",
    "model = GridSearchCV(pipe, param_grid, cv=5)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy, precision, recall = evaluate_model(model, X_train_scaled_perturbed, y_train_perturbed, X_test_scaled_perturbed, y_test_perturbed)\n",
    "print(f\"Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}\")\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, \"model_pca_perturbed.pkl\")\n",
    "\n",
    "results.append({\"model\": \"LogisticRegression\", \"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"params\": model.best_params_, \"n_components\": model.best_params_[\"pca__n_components\"], \"dataset\": \"perturbed\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.91, Precision: 0.90, Recall: 0.70\n"
     ]
    }
   ],
   "source": [
    "# Train random forest model with perturbed features\n",
    "param_grid = {\"n_estimators\": [100, 200, 300], \"max_depth\": [10, 20, 30]}\n",
    "model = GridSearchCV(RandomForestClassifier(random_state=0), param_grid, cv=5)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy, precision, recall = evaluate_model(model, X_train_scaled_perturbed, y_train_perturbed, X_test_scaled_perturbed, y_test_perturbed)\n",
    "print(f\"Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}\")\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, \"model_rf_perturbed.pkl\")\n",
    "\n",
    "results.append({\"model\": \"RandomForest\", \"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"params\": model.best_params_, \"n_components\": None, \"dataset\": \"perturbed\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.88, Precision: 0.92, Recall: 0.52\n"
     ]
    }
   ],
   "source": [
    "# Train random forest model with PCA features and perturbed features\n",
    "param_grid = {\"randomforestclassifier__n_estimators\": [100, 200, 300, 400, 500], \"randomforestclassifier__max_depth\": [10, 20, 30], \"pca__n_components\": [0.95]}\n",
    "pipe = Pipeline([(\"pca\", PCA()), (\"randomforestclassifier\", RandomForestClassifier(random_state=0))])\n",
    "model = GridSearchCV(pipe, param_grid, cv=5)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy, precision, recall = evaluate_model(model, X_train_scaled_perturbed, y_train_perturbed, X_test_scaled_perturbed, y_test_perturbed)\n",
    "print(f\"Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}\")\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, \"model_rf_pca_perturbed.pkl\")\n",
    "\n",
    "results.append({\"model\": \"RandomForest\", \"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"params\": model.best_params_, \"n_components\": model.best_params_[\"pca__n_components\"], \"dataset\": \"perturbed\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>params</th>\n",
       "      <th>n_components</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.671642</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.853741</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.477612</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'pca__n_compone...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.701493</td>\n",
       "      <td>{'max_depth': 30, 'n_estimators': 100}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.874150</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.477612</td>\n",
       "      <td>{'pca__n_components': 40, 'randomforestclassif...</td>\n",
       "      <td>40.00</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.891156</td>\n",
       "      <td>0.796610</td>\n",
       "      <td>0.701493</td>\n",
       "      <td>{'C': 100}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>perturbed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.552239</td>\n",
       "      <td>{'logisticregression__C': 1, 'pca__n_component...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>perturbed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.914966</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.701493</td>\n",
       "      <td>{'max_depth': 20, 'n_estimators': 100}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>perturbed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.522388</td>\n",
       "      <td>{'pca__n_components': 0.95, 'randomforestclass...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>perturbed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model  accuracy  precision    recall  \\\n",
       "0  LogisticRegression  0.897959   0.849057  0.671642   \n",
       "1  LogisticRegression  0.853741   0.800000  0.477612   \n",
       "2        RandomForest  0.918367   0.921569  0.701493   \n",
       "3        RandomForest  0.874150   0.941176  0.477612   \n",
       "4  LogisticRegression  0.891156   0.796610  0.701493   \n",
       "5  LogisticRegression  0.877551   0.860465  0.552239   \n",
       "6        RandomForest  0.914966   0.903846  0.701493   \n",
       "7        RandomForest  0.880952   0.921053  0.522388   \n",
       "\n",
       "                                              params  n_components    dataset  \n",
       "0                                          {'C': 10}           NaN   original  \n",
       "1  {'logisticregression__C': 0.1, 'pca__n_compone...          0.95   original  \n",
       "2             {'max_depth': 30, 'n_estimators': 100}           NaN   original  \n",
       "3  {'pca__n_components': 40, 'randomforestclassif...         40.00   original  \n",
       "4                                         {'C': 100}           NaN  perturbed  \n",
       "5  {'logisticregression__C': 1, 'pca__n_component...          0.95  perturbed  \n",
       "6             {'max_depth': 20, 'n_estimators': 100}           NaN  perturbed  \n",
       "7  {'pca__n_components': 0.95, 'randomforestclass...          0.95  perturbed  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>original_shape_SurfaceVolumeRatio</td>\n",
       "      <td>0.086829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>original_shape_MeshVolume</td>\n",
       "      <td>0.064858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>original_shape_VoxelVolume</td>\n",
       "      <td>0.059586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>original_shape_Sphericity</td>\n",
       "      <td>0.033392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>original_glszm_LargeAreaHighGrayLevelEmphasis</td>\n",
       "      <td>0.030181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>original_gldm_DependenceNonUniformity</td>\n",
       "      <td>0.026946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>original_ngtdm_Coarseness</td>\n",
       "      <td>0.026722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>original_glrlm_RunLengthNonUniformity</td>\n",
       "      <td>0.025311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>original_shape_LeastAxisLength</td>\n",
       "      <td>0.023990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>original_shape_Maximum2DDiameterColumn</td>\n",
       "      <td>0.019635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>original_shape_MinorAxisLength</td>\n",
       "      <td>0.019149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>original_glrlm_GrayLevelNonUniformity</td>\n",
       "      <td>0.019027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>original_shape_Maximum2DDiameterSlice</td>\n",
       "      <td>0.018426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>original_shape_Maximum3DDiameter</td>\n",
       "      <td>0.015041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>original_shape_SurfaceArea</td>\n",
       "      <td>0.013429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>original_shape_Maximum2DDiameterRow</td>\n",
       "      <td>0.012956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>original_glszm_GrayLevelNonUniformity</td>\n",
       "      <td>0.011839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>original_gldm_LargeDependenceHighGrayLevelEmph...</td>\n",
       "      <td>0.011403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>original_shape_MajorAxisLength</td>\n",
       "      <td>0.011259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>original_shape_Flatness</td>\n",
       "      <td>0.011100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               feature  importance\n",
       "12                   original_shape_SurfaceVolumeRatio    0.086829\n",
       "8                            original_shape_MeshVolume    0.064858\n",
       "13                          original_shape_VoxelVolume    0.059586\n",
       "10                           original_shape_Sphericity    0.033392\n",
       "91       original_glszm_LargeAreaHighGrayLevelEmphasis    0.030181\n",
       "57               original_gldm_DependenceNonUniformity    0.026946\n",
       "103                          original_ngtdm_Coarseness    0.026722\n",
       "79               original_glrlm_RunLengthNonUniformity    0.025311\n",
       "2                       original_shape_LeastAxisLength    0.023990\n",
       "4               original_shape_Maximum2DDiameterColumn    0.019635\n",
       "9                       original_shape_MinorAxisLength    0.019149\n",
       "70               original_glrlm_GrayLevelNonUniformity    0.019027\n",
       "6                original_shape_Maximum2DDiameterSlice    0.018426\n",
       "7                     original_shape_Maximum3DDiameter    0.015041\n",
       "11                          original_shape_SurfaceArea    0.013429\n",
       "5                  original_shape_Maximum2DDiameterRow    0.012956\n",
       "86               original_glszm_GrayLevelNonUniformity    0.011839\n",
       "64   original_gldm_LargeDependenceHighGrayLevelEmph...    0.011403\n",
       "3                       original_shape_MajorAxisLength    0.011259\n",
       "1                              original_shape_Flatness    0.011100"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get feature importances from the best random forest model\n",
    "model = joblib.load(\"model_rf_perturbed.pkl\")\n",
    "importances = model.best_estimator_.feature_importances_\n",
    "importances_df = pd.DataFrame({\"feature\": data_train.filter(regex=\"original\").columns, \"importance\": importances})\n",
    "importances_df = importances_df.sort_values(\"importance\", ascending=False)\n",
    "importances_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1174, 93)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a model without shape features\n",
    "X = data_train.filter(regex=\"original\").drop(columns=data_train.filter(regex=\"shape\").columns).values\n",
    "y = data_train[\"Grade\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.89, Precision: 0.81, Recall: 0.66\n"
     ]
    }
   ],
   "source": [
    "\n",
    "param_grid = {\"C\": [0.1, 1, 10, 100]}\n",
    "model = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=5)\n",
    "\n",
    "accuracy, precision, recall = evaluate_model(model, X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "print(f\"Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}\")\n",
    "\n",
    "results.append({\"model\": \"LogisticRegression\", \"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"params\": model.best_params_, \"n_components\": None, \"dataset\": \"original_no_shape\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85, Precision: 0.82, Recall: 0.42\n"
     ]
    }
   ],
   "source": [
    "# Train a model without shape features and with PCA\n",
    "param_grid = {\"logisticregression__C\": [0.1, 1, 10, 100], \"pca__n_components\": [0.95]}\n",
    "pipe = Pipeline([(\"pca\", PCA()), (\"logisticregression\", LogisticRegression(max_iter=1000))])\n",
    "model = GridSearchCV(pipe, param_grid, cv=5)\n",
    "\n",
    "accuracy, precision, recall = evaluate_model(model, X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "print(f\"Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}\")\n",
    "\n",
    "results.append({\"model\": \"LogisticRegression\", \"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"params\": model.best_params_, \"n_components\": model.best_params_[\"pca__n_components\"], \"dataset\": \"original_no_shape\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.87, Precision: 0.74, Recall: 0.69\n"
     ]
    }
   ],
   "source": [
    "# Train a model without shape features and with perturbed features\n",
    "X_perturbed = feat_train_perturbed.filter(regex=\"original\").drop(columns=feat_train_perturbed.filter(regex=\"shape\").columns).values\n",
    "y_perturbed = data_train[\"Grade\"].values\n",
    "\n",
    "X_train_perturbed, X_test_perturbed, y_train_perturbed, y_test_perturbed = train_test_split(X_perturbed, y_perturbed, test_size=0.2, random_state=0)\n",
    "X_train_scaled_perturbed = scaler.fit_transform(X_train_perturbed)\n",
    "X_test_scaled_perturbed = scaler.transform(X_test_perturbed)\n",
    "\n",
    "param_grid = {\"C\": [0.1, 1, 10, 100]}\n",
    "model = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=5)\n",
    "\n",
    "accuracy, precision, recall = evaluate_model(model, X_train_scaled_perturbed, y_train_perturbed, X_test_scaled_perturbed, y_test_perturbed)\n",
    "print(f\"Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}\")\n",
    "\n",
    "results.append({\"model\": \"LogisticRegression\", \"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"params\": model.best_params_, \"n_components\": None, \"dataset\": \"perturbed_no_shape\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.87, Precision: 0.87, Recall: 0.49\n"
     ]
    }
   ],
   "source": [
    "# Train a model without shape features and with PCA and perturbed features\n",
    "param_grid = {\"logisticregression__C\": [0.1, 1, 10, 100], \"pca__n_components\": [0.95]}\n",
    "pipe = Pipeline([(\"pca\", PCA()), (\"logisticregression\", LogisticRegression(max_iter=1000))])\n",
    "model = GridSearchCV(pipe, param_grid, cv=5)\n",
    "\n",
    "accuracy, precision, recall = evaluate_model(model, X_train_scaled_perturbed, y_train_perturbed, X_test_scaled_perturbed, y_test_perturbed)\n",
    "print(f\"Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}\")\n",
    "\n",
    "results.append({\"model\": \"LogisticRegression\", \"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"params\": model.best_params_, \"n_components\": model.best_params_[\"pca__n_components\"], \"dataset\": \"perturbed_no_shape\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.86, Precision: 0.75, Recall: 0.57\n"
     ]
    }
   ],
   "source": [
    "# Train a model without shape features and with random forest   \n",
    "param_grid = {\"n_estimators\": [100, 200, 300], \"max_depth\": [10, 20, 30]}\n",
    "model = GridSearchCV(RandomForestClassifier(random_state=0), param_grid, cv=5)\n",
    "\n",
    "accuracy, precision, recall = evaluate_model(model, X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "print(f\"Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}\")\n",
    "\n",
    "results.append({\"model\": \"RandomForest\", \"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"params\": model.best_params_, \"n_components\": None, \"dataset\": \"original_no_shape\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.86, Precision: 0.84, Recall: 0.46\n",
      "Accuracy: 0.87, Precision: 0.89, Recall: 0.51\n"
     ]
    }
   ],
   "source": [
    "# Train a model without shape features and with PCA and random forest\n",
    "param_grid = {\"randomforestclassifier__n_estimators\": [100, 200, 300, 400, 500], \"randomforestclassifier__max_depth\": [10, 20, 30], \"pca__n_components\": [0.95]}\n",
    "pipe = Pipeline([(\"pca\", PCA()), (\"randomforestclassifier\", RandomForestClassifier(random_state=0))])\n",
    "model = GridSearchCV(pipe, param_grid, cv=5)\n",
    "\n",
    "accuracy, precision, recall = evaluate_model(model, X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "print(f\"Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}\")\n",
    "\n",
    "results.append({\"model\": \"RandomForest\", \"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"params\": model.best_params_, \"n_components\": model.best_params_[\"pca__n_components\"], \"dataset\": \"original_no_shape\"})\n",
    "\n",
    "# Train a model without shape features and with perturbed features and random forest\n",
    "param_grid = {\"n_estimators\": [100, 200, 300], \"max_depth\": [10, 20, 30]}\n",
    "model = GridSearchCV(RandomForestClassifier(random_state=0), param_grid, cv=5)\n",
    "\n",
    "accuracy, precision, recall = evaluate_model(model, X_train_scaled_perturbed, y_train_perturbed, X_test_scaled_perturbed, y_test_perturbed)\n",
    "print(f\"Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}\")\n",
    "\n",
    "results.append({\"model\": \"RandomForest\", \"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"params\": model.best_params_, \"n_components\": None, \"dataset\": \"perturbed_no_shape\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.87, Precision: 0.85, Recall: 0.51\n"
     ]
    }
   ],
   "source": [
    "# Train a model without shape features and with PCA and perturbed features and random forest\n",
    "param_grid = {\"randomforestclassifier__n_estimators\": [100, 200, 300, 400, 500], \"randomforestclassifier__max_depth\": [10, 20, 30], \"pca__n_components\": [0.95]}\n",
    "pipe = Pipeline([(\"pca\", PCA()), (\"randomforestclassifier\", RandomForestClassifier(random_state=0))])\n",
    "model = GridSearchCV(pipe, param_grid, cv=5)\n",
    "\n",
    "accuracy, precision, recall = evaluate_model(model, X_train_scaled_perturbed, y_train_perturbed, X_test_scaled_perturbed, y_test_perturbed)\n",
    "print(f\"Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}\")\n",
    "\n",
    "results.append({\"model\": \"RandomForest\", \"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"params\": model.best_params_, \"n_components\": model.best_params_[\"pca__n_components\"], \"dataset\": \"perturbed_no_shape\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>params</th>\n",
       "      <th>n_components</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.671642</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.853741</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.477612</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'pca__n_compone...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.701493</td>\n",
       "      <td>{'max_depth': 30, 'n_estimators': 100}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.874150</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.477612</td>\n",
       "      <td>{'pca__n_components': 40, 'randomforestclassif...</td>\n",
       "      <td>40.00</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.891156</td>\n",
       "      <td>0.796610</td>\n",
       "      <td>0.701493</td>\n",
       "      <td>{'C': 100}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>perturbed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.552239</td>\n",
       "      <td>{'logisticregression__C': 1, 'pca__n_component...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>perturbed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.914966</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.701493</td>\n",
       "      <td>{'max_depth': 20, 'n_estimators': 100}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>perturbed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.522388</td>\n",
       "      <td>{'pca__n_components': 0.95, 'randomforestclass...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>perturbed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.887755</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.656716</td>\n",
       "      <td>{'C': 100}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>original_no_shape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.846939</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.417910</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'pca__n_compone...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>original_no_shape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.874150</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.686567</td>\n",
       "      <td>{'C': 100}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>perturbed_no_shape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.867347</td>\n",
       "      <td>0.868421</td>\n",
       "      <td>0.492537</td>\n",
       "      <td>{'logisticregression__C': 1, 'pca__n_component...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>perturbed_no_shape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.567164</td>\n",
       "      <td>{'max_depth': 20, 'n_estimators': 300}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>original_no_shape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.462687</td>\n",
       "      <td>{'pca__n_components': 0.95, 'randomforestclass...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>original_no_shape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.874150</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.507463</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 300}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>perturbed no shape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.867347</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.507463</td>\n",
       "      <td>{'pca__n_components': 0.95, 'randomforestclass...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>perturbed_no_shape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.874150</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.507463</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 300}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>perturbed no shape</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  accuracy  precision    recall  \\\n",
       "0   LogisticRegression  0.897959   0.849057  0.671642   \n",
       "1   LogisticRegression  0.853741   0.800000  0.477612   \n",
       "2         RandomForest  0.918367   0.921569  0.701493   \n",
       "3         RandomForest  0.874150   0.941176  0.477612   \n",
       "4   LogisticRegression  0.891156   0.796610  0.701493   \n",
       "5   LogisticRegression  0.877551   0.860465  0.552239   \n",
       "6         RandomForest  0.914966   0.903846  0.701493   \n",
       "7         RandomForest  0.880952   0.921053  0.522388   \n",
       "8   LogisticRegression  0.887755   0.814815  0.656716   \n",
       "9   LogisticRegression  0.846939   0.823529  0.417910   \n",
       "10  LogisticRegression  0.874150   0.741935  0.686567   \n",
       "11  LogisticRegression  0.867347   0.868421  0.492537   \n",
       "12        RandomForest  0.857143   0.745098  0.567164   \n",
       "13        RandomForest  0.857143   0.837838  0.462687   \n",
       "14        RandomForest  0.874150   0.894737  0.507463   \n",
       "15        RandomForest  0.867347   0.850000  0.507463   \n",
       "16        RandomForest  0.874150   0.894737  0.507463   \n",
       "\n",
       "                                               params  n_components  \\\n",
       "0                                           {'C': 10}           NaN   \n",
       "1   {'logisticregression__C': 0.1, 'pca__n_compone...          0.95   \n",
       "2              {'max_depth': 30, 'n_estimators': 100}           NaN   \n",
       "3   {'pca__n_components': 40, 'randomforestclassif...         40.00   \n",
       "4                                          {'C': 100}           NaN   \n",
       "5   {'logisticregression__C': 1, 'pca__n_component...          0.95   \n",
       "6              {'max_depth': 20, 'n_estimators': 100}           NaN   \n",
       "7   {'pca__n_components': 0.95, 'randomforestclass...          0.95   \n",
       "8                                          {'C': 100}           NaN   \n",
       "9   {'logisticregression__C': 0.1, 'pca__n_compone...          0.95   \n",
       "10                                         {'C': 100}           NaN   \n",
       "11  {'logisticregression__C': 1, 'pca__n_component...          0.95   \n",
       "12             {'max_depth': 20, 'n_estimators': 300}           NaN   \n",
       "13  {'pca__n_components': 0.95, 'randomforestclass...          0.95   \n",
       "14             {'max_depth': 10, 'n_estimators': 300}           NaN   \n",
       "15  {'pca__n_components': 0.95, 'randomforestclass...          0.95   \n",
       "16             {'max_depth': 10, 'n_estimators': 300}           NaN   \n",
       "\n",
       "               dataset  \n",
       "0             original  \n",
       "1             original  \n",
       "2             original  \n",
       "3             original  \n",
       "4            perturbed  \n",
       "5            perturbed  \n",
       "6            perturbed  \n",
       "7            perturbed  \n",
       "8    original_no_shape  \n",
       "9    original_no_shape  \n",
       "10  perturbed_no_shape  \n",
       "11  perturbed_no_shape  \n",
       "12   original_no_shape  \n",
       "13   original_no_shape  \n",
       "14  perturbed no shape  \n",
       "15  perturbed_no_shape  \n",
       "16  perturbed no shape  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>params</th>\n",
       "      <th>n_components</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.671642</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.891156</td>\n",
       "      <td>0.796610</td>\n",
       "      <td>0.701493</td>\n",
       "      <td>{'C': 100}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>perturbed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.887755</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.656716</td>\n",
       "      <td>{'C': 100}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>original_no_shape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.552239</td>\n",
       "      <td>{'logisticregression__C': 1, 'pca__n_component...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>perturbed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.874150</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.686567</td>\n",
       "      <td>{'C': 100}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>perturbed_no_shape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.867347</td>\n",
       "      <td>0.868421</td>\n",
       "      <td>0.492537</td>\n",
       "      <td>{'logisticregression__C': 1, 'pca__n_component...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>perturbed_no_shape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.853741</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.477612</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'pca__n_compone...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.846939</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.417910</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'pca__n_compone...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>original_no_shape</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  accuracy  precision    recall  \\\n",
       "0   LogisticRegression  0.897959   0.849057  0.671642   \n",
       "4   LogisticRegression  0.891156   0.796610  0.701493   \n",
       "8   LogisticRegression  0.887755   0.814815  0.656716   \n",
       "5   LogisticRegression  0.877551   0.860465  0.552239   \n",
       "10  LogisticRegression  0.874150   0.741935  0.686567   \n",
       "11  LogisticRegression  0.867347   0.868421  0.492537   \n",
       "1   LogisticRegression  0.853741   0.800000  0.477612   \n",
       "9   LogisticRegression  0.846939   0.823529  0.417910   \n",
       "\n",
       "                                               params  n_components  \\\n",
       "0                                           {'C': 10}           NaN   \n",
       "4                                          {'C': 100}           NaN   \n",
       "8                                          {'C': 100}           NaN   \n",
       "5   {'logisticregression__C': 1, 'pca__n_component...          0.95   \n",
       "10                                         {'C': 100}           NaN   \n",
       "11  {'logisticregression__C': 1, 'pca__n_component...          0.95   \n",
       "1   {'logisticregression__C': 0.1, 'pca__n_compone...          0.95   \n",
       "9   {'logisticregression__C': 0.1, 'pca__n_compone...          0.95   \n",
       "\n",
       "               dataset  \n",
       "0             original  \n",
       "4            perturbed  \n",
       "8    original_no_shape  \n",
       "5            perturbed  \n",
       "10  perturbed_no_shape  \n",
       "11  perturbed_no_shape  \n",
       "1             original  \n",
       "9    original_no_shape  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[results_df['model'] == 'LogisticRegression'].sort_values('accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = results_df[results_df['model'] == 'RandomForest'].sort_values('accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.to_latex(\"rf_results.tex\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>n_components</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.701493</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.671642</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.887755</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.656716</td>\n",
       "      <td>original_no_shape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>40.00</td>\n",
       "      <td>0.874150</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.477612</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.567164</td>\n",
       "      <td>original_no_shape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.462687</td>\n",
       "      <td>original_no_shape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.853741</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.477612</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.846939</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.417910</td>\n",
       "      <td>original_no_shape</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  n_components  accuracy  precision    recall  \\\n",
       "2         RandomForest           NaN  0.918367   0.921569  0.701493   \n",
       "0   LogisticRegression           NaN  0.897959   0.849057  0.671642   \n",
       "8   LogisticRegression           NaN  0.887755   0.814815  0.656716   \n",
       "3         RandomForest         40.00  0.874150   0.941176  0.477612   \n",
       "12        RandomForest           NaN  0.857143   0.745098  0.567164   \n",
       "13        RandomForest          0.95  0.857143   0.837838  0.462687   \n",
       "1   LogisticRegression          0.95  0.853741   0.800000  0.477612   \n",
       "9   LogisticRegression          0.95  0.846939   0.823529  0.417910   \n",
       "\n",
       "              dataset  \n",
       "2            original  \n",
       "0            original  \n",
       "8   original_no_shape  \n",
       "3            original  \n",
       "12  original_no_shape  \n",
       "13  original_no_shape  \n",
       "1            original  \n",
       "9   original_no_shape  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[['model', 'n_components', 'accuracy', 'precision', 'recall', 'dataset']].where(results_df['dataset'].isin(['original','original_no_shape'])).sort_values('accuracy', ascending=False).dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>n_components</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.914966</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.701493</td>\n",
       "      <td>perturbed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.891156</td>\n",
       "      <td>0.796610</td>\n",
       "      <td>0.701493</td>\n",
       "      <td>perturbed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.522388</td>\n",
       "      <td>perturbed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.552239</td>\n",
       "      <td>perturbed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.874150</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.686567</td>\n",
       "      <td>perturbed_no_shape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.867347</td>\n",
       "      <td>0.868421</td>\n",
       "      <td>0.492537</td>\n",
       "      <td>perturbed_no_shape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.867347</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.507463</td>\n",
       "      <td>perturbed_no_shape</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  n_components  accuracy  precision    recall  \\\n",
       "6         RandomForest           NaN  0.914966   0.903846  0.701493   \n",
       "4   LogisticRegression           NaN  0.891156   0.796610  0.701493   \n",
       "7         RandomForest          0.95  0.880952   0.921053  0.522388   \n",
       "5   LogisticRegression          0.95  0.877551   0.860465  0.552239   \n",
       "10  LogisticRegression           NaN  0.874150   0.741935  0.686567   \n",
       "11  LogisticRegression          0.95  0.867347   0.868421  0.492537   \n",
       "15        RandomForest          0.95  0.867347   0.850000  0.507463   \n",
       "\n",
       "               dataset  \n",
       "6            perturbed  \n",
       "4            perturbed  \n",
       "7            perturbed  \n",
       "5            perturbed  \n",
       "10  perturbed_no_shape  \n",
       "11  perturbed_no_shape  \n",
       "15  perturbed_no_shape  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[['model', 'n_components', 'accuracy', 'precision', 'recall', 'dataset']].where(results_df['dataset'].isin(['perturbed','perturbed_no_shape'])).sort_values('accuracy', ascending=False).dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsi",
   "language": "python",
   "name": "dsi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
